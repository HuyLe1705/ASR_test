import streamlit as st
import os
import tempfile
from faster_whisper import WhisperModel

NEON_GREEN = "\033[92m"   # Xanh s√°ng
RESET_COLOR = "\033[0m"   # Reset v·ªÅ m·∫∑c ƒë·ªãnh

def transcribe_chunk(model, file_path):
    segments, info = model.transcribe(file_path, language="en", vad_filter=True)
    text = "".join([segment.text for segment in segments])
    return text

# Giao di·ªán Streamlit
st.title("üé§ Real-time Voice Transcription (Whisper AI)")
st.markdown("Upload audio file (.wav, .mp3) ƒë·ªÉ chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n")

# Ch·ªçn k√≠ch th∆∞·ªõc model
model_size = st.selectbox("Ch·ªçn model:", ["base", "small", "medium", "large-v3"], index=3)
device = "cuda" if st.checkbox("D√πng GPU (CUDA)", value=True) else "cpu"

# T·∫£i model Whisper
@st.cache_resource
def load_model(model_size, device):
    return WhisperModel(model_size, device=device, compute_type="float16" if device == "cuda" else "int8")

model = load_model(model_size, device)
st.success(f"‚úÖ Model `{model_size}` ƒë√£ s·∫µn s√†ng tr√™n {device.upper()}")

# Upload file audio
uploaded_file = st.file_uploader("Ch·ªçn t·ªáp √¢m thanh", type=["wav", "mp3", "m4a"])

if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    st.info("‚è≥ ƒêang x·ª≠ l√Ω √¢m thanh...")
    transcription = transcribe_chunk(model, tmp_path)

    if transcription.strip():
        st.markdown(f"<span style='color:limegreen; font-weight:bold;'>{transcription}</span>", unsafe_allow_html=True)

        # Ghi log v√†o file
        with open("log.txt", "a", encoding="utf-8") as log_file:
            log_file.write(transcription + "\n")

        st.download_button("üì• T·∫£i log.txt", data=transcription, file_name="log.txt")
    else:
        st.warning("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c gi·ªçng n√≥i trong ƒëo·∫°n audio.")

    os.remove(tmp_path)
